{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Evaluation_Tuning_Improve.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGZljdPhuvhz"
      },
      "source": [
        "# Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DsBCmR87p__"
      },
      "source": [
        "Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgLot6R75ajV"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PzgWDiVCJOG"
      },
      "source": [
        "# Deep Learning Libraries\n",
        "import keras\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaSeUwRd7sJb"
      },
      "source": [
        "Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiBpNJSk6YiX"
      },
      "source": [
        "dataset = pd.read_csv(\"Churn_Modelling.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qstkUml06jgM"
      },
      "source": [
        "x = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a5juG4B8VmI"
      },
      "source": [
        "Encode Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe1eUWOg8aWz"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "encoder = LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpWJrbIJ8XcM"
      },
      "source": [
        "# Encode Gender\n",
        "x[:, 2] = encoder.fit_transform(x[:, 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwMFdds39Lv8"
      },
      "source": [
        "# Because geography is not ordinal\n",
        "# And there are more than 2 values in it\n",
        "# Use OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "# Drop one dummy variable to avoid Dummy Variable Trap\n",
        "x = np.array(ct.fit_transform(x))\n",
        "x = x[:, 1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUVMLIVD7xHu"
      },
      "source": [
        "Splitting the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTKS8hvF7h0r"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIjD9FBjA3L6"
      },
      "source": [
        "Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV8SxwgoArK9"
      },
      "source": [
        "# Ease calculations resources\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwbOXWcuuq7J"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z01e_FG8vFzo"
      },
      "source": [
        "Function to Build and Evaluate the Architecture of the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkq-UGFXu1RV"
      },
      "source": [
        "def build_ann_architecture():\n",
        "  # Initializing Artificial Neural Networks\n",
        "  classifier = Sequential()\n",
        "  # Adding Input Layer\n",
        "  classifier.add(Dense(units=6, activation='relu', kernel_initializer='uniform', input_dim = 11))\n",
        "  # Hidden Layers\n",
        "  classifier.add(Dense(units=6, activation='relu', kernel_initializer='uniform'))\n",
        "  # Output Layers\n",
        "  classifier.add(Dense(units=1, activation='sigmoid', kernel_initializer='uniform'))\n",
        "  # Similar to applying gradiant descent to all the layers\n",
        "  classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip0tP-GQk_IP"
      },
      "source": [
        "K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqsJM6yflCGT"
      },
      "source": [
        "classifier = KerasClassifier(build_fn = build_ann_architecture, batch_size = 10, nb_epoch = 100)\n",
        "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10, n_jobs = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUC5rOepn3iM"
      },
      "source": [
        "mean = accuracies.mean()\n",
        "std = accuracies.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVuDWm2vulNx"
      },
      "source": [
        "# Dropout Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lybhQn3QvJxq"
      },
      "source": [
        "Function to Build the Architecture of the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjT0ZQZimCY3"
      },
      "source": [
        "def build_ann_architecture():\n",
        "  # Reduce Overfitting -> High Variance, Accuracy on Training Set >>> Accuracy on Test Set\n",
        "  # To reduce overfitting, use Dropout Regularization\n",
        "  # to prevent the neuron learning too much from each other\n",
        "  # The neuron is killed and rewritten in each iteration, never kill more than 0.5 neurons\n",
        "  # Apply the regularization to all layers to avoid overfitting\n",
        "\n",
        "  # Initializing Artificial Neural Networks\n",
        "  classifier = Sequential()\n",
        "  # Adding Input Layer\n",
        "  classifier.add(Dense(units=6, activation='relu', kernel_initializer='uniform', input_dim = 11))\n",
        "  classifier.add(Dropout(p = 0.1))\n",
        "  # Hidden Layers\n",
        "  classifier.add(Dense(units=6, activation='relu', kernel_initializer='uniform'))\n",
        "  classifier.add(Dropout(p = 0.1))\n",
        "  # Output Layers\n",
        "  classifier.add(Dense(units=1, activation='sigmoid', kernel_initializer='uniform'))\n",
        "  # Similar to applying gradiant descent to all the layers\n",
        "  classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k20oZtzLudt3"
      },
      "source": [
        "# Tuning the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU1s5LlsvNLJ"
      },
      "source": [
        "Dictionary to Contain Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQeABgcmvMFN"
      },
      "source": [
        "hyperparams = {\"batch_size\": [10, 25, 32],\n",
        "               \"nb_epoch\": [100, 250, 500],\n",
        "               \"optimizer\": [\"adam\", \"rmsprop\"]\n",
        "               }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty63coDDvK1w"
      },
      "source": [
        "Function to Build and Tune the Architecture of the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0IxnWaLuMcl"
      },
      "source": [
        "def build_ann_architecture(optimizer):\n",
        "  # Initializing Artificial Neural Networks\n",
        "  classifier = Sequential()\n",
        "  # Adding Input Layer\n",
        "  classifier.add(Dense(units=6, activation='relu', kernel_initializer='uniform', input_dim = 11))\n",
        "  classifier.add(Dropout(0.2))\n",
        "  # Hidden Layers\n",
        "  classifier.add(Dense(units=6, activation='relu', kernel_initializer='uniform'))\n",
        "  classifier.add(Dropout(0.2))\n",
        "  # Output Layers\n",
        "  classifier.add(Dense(units=1, activation='relu', kernel_initializer='uniform'))\n",
        "  # Similar to applying gradiant descent to all the layers\n",
        "  classifier.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "  return classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNtaldlbuWD-"
      },
      "source": [
        "# Remove all the hyperparameters for the tuning\n",
        "classifier = KerasClassifier(build_fn = build_ann_architecture)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQJGF91yxH_2"
      },
      "source": [
        "Use Grid Search to do Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-ypCE57wZzM",
        "outputId": "381d592b-227f-455e-8766-0cb37cedf210"
      },
      "source": [
        "grid_search = GridSearchCV(estimator = classifier, param_grid = hyperparams, scoring = \"accuracy\", cv = 10)\n",
        "# Fit the Grid Search\n",
        "grid_search = grid_search.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "720/720 [==============================] - 1s 957us/step - loss: 0.6719 - accuracy: 0.7980\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "720/720 [==============================] - 1s 1ms/step - loss: 3.1064 - accuracy: 0.7986\n",
            "720/720 [==============================] - 1s 972us/step - loss: 0.6673 - accuracy: 0.8011\n",
            "720/720 [==============================] - 1s 982us/step - loss: 0.6782 - accuracy: 0.7975\n",
            "720/720 [==============================] - 1s 945us/step - loss: 0.8204 - accuracy: 0.7949\n",
            "720/720 [==============================] - 1s 972us/step - loss: 3.1006 - accuracy: 0.7990\n",
            "720/720 [==============================] - 1s 938us/step - loss: 3.0505 - accuracy: 0.8022\n",
            "720/720 [==============================] - 1s 946us/step - loss: 0.7962 - accuracy: 0.7874\n",
            "720/720 [==============================] - 1s 942us/step - loss: 3.0005 - accuracy: 0.8055\n",
            "720/720 [==============================] - 1s 948us/step - loss: 0.7508 - accuracy: 0.8002\n",
            "720/720 [==============================] - 1s 964us/step - loss: 3.0190 - accuracy: 0.8043\n",
            "720/720 [==============================] - 1s 951us/step - loss: 3.1639 - accuracy: 0.7949\n",
            "720/720 [==============================] - 1s 951us/step - loss: 0.6428 - accuracy: 0.8035\n",
            "720/720 [==============================] - 1s 965us/step - loss: 0.7600 - accuracy: 0.7977\n",
            "720/720 [==============================] - 1s 945us/step - loss: 0.6548 - accuracy: 0.7936\n",
            "720/720 [==============================] - 1s 954us/step - loss: 3.1739 - accuracy: 0.7942\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 3.0878 - accuracy: 0.7998\n",
            "720/720 [==============================] - 1s 960us/step - loss: 0.7103 - accuracy: 0.7978\n",
            "720/720 [==============================] - 1s 973us/step - loss: 3.0582 - accuracy: 0.8017\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 3.1240 - accuracy: 0.7975\n",
            "720/720 [==============================] - 1s 962us/step - loss: 0.7282 - accuracy: 0.7926\n",
            "720/720 [==============================] - 1s 951us/step - loss: 0.8220 - accuracy: 0.8030\n",
            "720/720 [==============================] - 1s 968us/step - loss: 0.9000 - accuracy: 0.7989\n",
            "720/720 [==============================] - 1s 954us/step - loss: 0.7445 - accuracy: 0.7959\n",
            "720/720 [==============================] - 1s 950us/step - loss: 0.9318 - accuracy: 0.7904\n",
            "720/720 [==============================] - 1s 961us/step - loss: 3.1930 - accuracy: 0.7930\n",
            "720/720 [==============================] - 1s 953us/step - loss: 0.9556 - accuracy: 0.7877\n",
            "720/720 [==============================] - 1s 956us/step - loss: 3.1105 - accuracy: 0.7983\n",
            "720/720 [==============================] - 1s 959us/step - loss: 0.6863 - accuracy: 0.7985\n",
            "720/720 [==============================] - 1s 977us/step - loss: 3.1825 - accuracy: 0.7937\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.7064 - accuracy: 0.7956\n",
            "720/720 [==============================] - 1s 977us/step - loss: 0.6455 - accuracy: 0.8031\n",
            "720/720 [==============================] - 1s 998us/step - loss: 0.5913 - accuracy: 0.7915\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 3.0121 - accuracy: 0.8047\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.6761 - accuracy: 0.7937\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.8373 - accuracy: 0.7854\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.6614 - accuracy: 0.7984\n",
            "720/720 [==============================] - 1s 952us/step - loss: 0.7131 - accuracy: 0.7890\n",
            "720/720 [==============================] - 1s 972us/step - loss: 0.7018 - accuracy: 0.7959\n",
            "720/720 [==============================] - 1s 997us/step - loss: 3.0685 - accuracy: 0.8011\n",
            "720/720 [==============================] - 1s 955us/step - loss: 3.0299 - accuracy: 0.8036\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 3.1412 - accuracy: 0.7964\n",
            "720/720 [==============================] - 1s 969us/step - loss: 0.6949 - accuracy: 0.7932\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.6208 - accuracy: 0.8055\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.8329 - accuracy: 0.7876\n",
            "720/720 [==============================] - 1s 971us/step - loss: 0.6498 - accuracy: 0.8061\n",
            "720/720 [==============================] - 1s 921us/step - loss: 0.7084 - accuracy: 0.7995\n",
            "720/720 [==============================] - 1s 986us/step - loss: 0.7327 - accuracy: 0.7940\n",
            "720/720 [==============================] - 1s 964us/step - loss: 0.7017 - accuracy: 0.7984\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 3.1382 - accuracy: 0.7965\n",
            "720/720 [==============================] - 1s 999us/step - loss: 0.6838 - accuracy: 0.8042\n",
            "720/720 [==============================] - 1s 967us/step - loss: 0.6751 - accuracy: 0.8008\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.6784 - accuracy: 0.8034\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 3.0642 - accuracy: 0.8014\n",
            "720/720 [==============================] - 1s 999us/step - loss: 3.1909 - accuracy: 0.7931\n",
            "720/720 [==============================] - 2s 1ms/step - loss: 3.1165 - accuracy: 0.7980\n",
            "720/720 [==============================] - 1s 966us/step - loss: 0.5897 - accuracy: 0.8038\n",
            "720/720 [==============================] - 1s 964us/step - loss: 0.6719 - accuracy: 0.7950\n",
            "720/720 [==============================] - 1s 974us/step - loss: 0.6021 - accuracy: 0.7996\n",
            "720/720 [==============================] - 1s 1ms/step - loss: 0.6631 - accuracy: 0.7957\n",
            "288/288 [==============================] - 1s 989us/step - loss: 0.9296 - accuracy: 0.7882\n",
            "288/288 [==============================] - 1s 981us/step - loss: 0.9015 - accuracy: 0.7935\n",
            "288/288 [==============================] - 1s 983us/step - loss: 0.9141 - accuracy: 0.7896\n",
            "288/288 [==============================] - 1s 992us/step - loss: 0.8486 - accuracy: 0.8010\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 3.2167 - accuracy: 0.7915\n",
            "288/288 [==============================] - 1s 999us/step - loss: 0.8939 - accuracy: 0.7883\n",
            "288/288 [==============================] - 1s 957us/step - loss: 0.8567 - accuracy: 0.7960\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.9312 - accuracy: 0.7982\n",
            "288/288 [==============================] - 1s 994us/step - loss: 0.8481 - accuracy: 0.7972\n",
            "288/288 [==============================] - 1s 943us/step - loss: 0.9105 - accuracy: 0.7923\n",
            "288/288 [==============================] - 1s 988us/step - loss: 3.0640 - accuracy: 0.8014\n",
            "288/288 [==============================] - 1s 994us/step - loss: 0.8959 - accuracy: 0.7923\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8190 - accuracy: 0.7924\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 3.2388 - accuracy: 0.7900\n",
            "288/288 [==============================] - 1s 974us/step - loss: 0.7295 - accuracy: 0.7923\n",
            "288/288 [==============================] - 1s 985us/step - loss: 0.9324 - accuracy: 0.7950\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.7642 - accuracy: 0.8041\n",
            "288/288 [==============================] - 1s 995us/step - loss: 0.8206 - accuracy: 0.7977\n",
            "288/288 [==============================] - 1s 993us/step - loss: 0.7205 - accuracy: 0.7990\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.9941 - accuracy: 0.7801\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8821 - accuracy: 0.7929\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.9540 - accuracy: 0.7943\n",
            "288/288 [==============================] - 1s 983us/step - loss: 0.8365 - accuracy: 0.7980\n",
            "288/288 [==============================] - 1s 973us/step - loss: 0.8377 - accuracy: 0.7914\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8695 - accuracy: 0.7993\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8873 - accuracy: 0.7942\n",
            "288/288 [==============================] - 1s 988us/step - loss: 0.8550 - accuracy: 0.7996\n",
            "288/288 [==============================] - 1s 972us/step - loss: 3.1514 - accuracy: 0.7957\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 3.1719 - accuracy: 0.7944\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8989 - accuracy: 0.7970\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8342 - accuracy: 0.7952\n",
            "288/288 [==============================] - 1s 991us/step - loss: 0.8207 - accuracy: 0.7945\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.7717 - accuracy: 0.7990\n",
            "288/288 [==============================] - 1s 940us/step - loss: 0.8481 - accuracy: 0.7983\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8584 - accuracy: 0.7977\n",
            "288/288 [==============================] - 1s 973us/step - loss: 0.8873 - accuracy: 0.7910\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8120 - accuracy: 0.7852\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.7856 - accuracy: 0.7992\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.7719 - accuracy: 0.7976\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8323 - accuracy: 0.7903\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 3.1846 - accuracy: 0.7935\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8727 - accuracy: 0.7977\n",
            "288/288 [==============================] - 1s 995us/step - loss: 0.8764 - accuracy: 0.7884\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 3.0003 - accuracy: 0.8055\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8531 - accuracy: 0.7973\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8804 - accuracy: 0.7949\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 3.1120 - accuracy: 0.7983\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.9304 - accuracy: 0.7985\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8345 - accuracy: 0.8001\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 3.1865 - accuracy: 0.7934\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.9260 - accuracy: 0.7947\n",
            "288/288 [==============================] - 1s 997us/step - loss: 0.7984 - accuracy: 0.7987\n",
            "288/288 [==============================] - 1s 974us/step - loss: 0.7909 - accuracy: 0.7970\n",
            "288/288 [==============================] - 1s 995us/step - loss: 3.1248 - accuracy: 0.7974\n",
            "288/288 [==============================] - 1s 979us/step - loss: 0.7917 - accuracy: 0.7982\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 3.1252 - accuracy: 0.7974\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 3.0994 - accuracy: 0.7991\n",
            "288/288 [==============================] - 1s 1ms/step - loss: 0.8115 - accuracy: 0.7967\n",
            "288/288 [==============================] - 1s 975us/step - loss: 0.7586 - accuracy: 0.7963\n",
            "288/288 [==============================] - 1s 997us/step - loss: 0.7837 - accuracy: 0.7960\n",
            "225/225 [==============================] - 1s 985us/step - loss: 0.9283 - accuracy: 0.7954\n",
            "225/225 [==============================] - 1s 998us/step - loss: 0.9362 - accuracy: 0.8008\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9684 - accuracy: 0.7955\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8912 - accuracy: 0.7955\n",
            "225/225 [==============================] - 1s 966us/step - loss: 0.9677 - accuracy: 0.7906\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9783 - accuracy: 0.7911\n",
            "225/225 [==============================] - 1s 964us/step - loss: 0.7921 - accuracy: 0.8037\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 3.1181 - accuracy: 0.7979\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 3.2625 - accuracy: 0.7885\n",
            "225/225 [==============================] - 1s 978us/step - loss: 0.8879 - accuracy: 0.8025\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 3.0809 - accuracy: 0.8003\n",
            "225/225 [==============================] - 1s 968us/step - loss: 1.0524 - accuracy: 0.7879\n",
            "225/225 [==============================] - 1s 991us/step - loss: 3.1315 - accuracy: 0.7970\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.7689 - accuracy: 0.8065\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8961 - accuracy: 0.7943\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.7105 - accuracy: 0.7989\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9936 - accuracy: 0.7851\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8868 - accuracy: 0.7948\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8553 - accuracy: 0.7942\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 3.1843 - accuracy: 0.7936\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8998 - accuracy: 0.8010\n",
            "225/225 [==============================] - 1s 997us/step - loss: 0.8625 - accuracy: 0.7939\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8178 - accuracy: 0.7979\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.7939 - accuracy: 0.8014\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 1.0753 - accuracy: 0.7942\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 1.0891 - accuracy: 0.7888\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8403 - accuracy: 0.8005\n",
            "225/225 [==============================] - 1s 975us/step - loss: 3.1435 - accuracy: 0.7962\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 3.1627 - accuracy: 0.7950\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8356 - accuracy: 0.7988\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9017 - accuracy: 0.8061\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8336 - accuracy: 0.7990\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9210 - accuracy: 0.7934\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.7599 - accuracy: 0.8037\n",
            "225/225 [==============================] - 1s 979us/step - loss: 3.1737 - accuracy: 0.7943\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 3.2647 - accuracy: 0.7883\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9421 - accuracy: 0.7969\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 3.1476 - accuracy: 0.7959\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8292 - accuracy: 0.7949\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8895 - accuracy: 0.7939\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 1.0169 - accuracy: 0.8005\n",
            "225/225 [==============================] - 1s 999us/step - loss: 0.9092 - accuracy: 0.7938\n",
            "225/225 [==============================] - 1s 988us/step - loss: 0.9179 - accuracy: 0.7996\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 3.1631 - accuracy: 0.7949\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9487 - accuracy: 0.7931\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9020 - accuracy: 0.7955\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9319 - accuracy: 0.7962\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 1.0275 - accuracy: 0.7894\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8102 - accuracy: 0.7956\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8115 - accuracy: 0.8051\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9578 - accuracy: 0.7922\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9712 - accuracy: 0.7936\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8182 - accuracy: 0.8008\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.7952 - accuracy: 0.7936\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 3.2270 - accuracy: 0.7908\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9202 - accuracy: 0.8003\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.9258 - accuracy: 0.7966\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8841 - accuracy: 0.7985\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.8550 - accuracy: 0.7956\n",
            "225/225 [==============================] - 1s 1ms/step - loss: 0.7852 - accuracy: 0.7946\n",
            "800/800 [==============================] - 1s 1ms/step - loss: 3.1772 - accuracy: 0.7940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKBr6ZqOxLkh"
      },
      "source": [
        "Get the Best Parameters after Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF7JkqwexOJj"
      },
      "source": [
        "best_params = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc29iwM6xXMz",
        "outputId": "98af9bbe-8dfb-4508-ec59-bd5995535e32"
      },
      "source": [
        "best_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 10, 'nb_epoch': 500, 'optimizer': 'rmsprop'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS0ZWPA0xZOD",
        "outputId": "75285d31-72b4-487c-9c30-c9db7e792959"
      },
      "source": [
        "best_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8026249999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}